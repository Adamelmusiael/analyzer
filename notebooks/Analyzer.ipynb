{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21aa943f-9d76-43b9-91f7-bcdec12b58f8",
   "metadata": {},
   "source": [
    "# Implementation!\n",
    "This notebook is simply an answer for your questions but using code. please take into account that the notebook below was made quickly due to lack of time - I can do even better then that ;)\n",
    "\n",
    "# Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27b49a69-c4ee-4e4b-9e25-5be38dc5da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs and tools\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import spacy\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from collections import Counter\n",
    "import language_tool_python\n",
    "import textstat\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import language_tool_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0afca0d1-5418-44f3-88ec-67f1c8d0508e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Adam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56c764fd-b173-4265-9685-f7db537e747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to display whole columns\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f81524ab-a4bc-4758-9fe2-4127ca87d232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hello, my name is John Doe. I’m calling from New York regarding an issue with my internet connection. It’s been down since Monday. Can you help me fix it?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uh, so like, um, I bought this thing and it’s, uh, not working. You know? Like, I need, uh, help or something.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Good afternoon, I’m Maria Sanchez. I placed an order last week and I haven't received a confirmation email. Could you check on that for me?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Yeah hi, yeah, the delivery never came. It’s, like, really annoying. Uh, I want a refund or whatever.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Hi, I’m Dr. Alan Turing, and I was inquiring about the status of my reimbursement request. It was submitted on the 10th of June. Please advise.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transcript_id  \\\n",
       "0              1   \n",
       "1              2   \n",
       "2              3   \n",
       "3              4   \n",
       "4              5   \n",
       "\n",
       "                                                                                                                                                   transcript  \n",
       "0  Hello, my name is John Doe. I’m calling from New York regarding an issue with my internet connection. It’s been down since Monday. Can you help me fix it?  \n",
       "1                                              Uh, so like, um, I bought this thing and it’s, uh, not working. You know? Like, I need, uh, help or something.  \n",
       "2                 Good afternoon, I’m Maria Sanchez. I placed an order last week and I haven't received a confirmation email. Could you check on that for me?  \n",
       "3                                                       Yeah hi, yeah, the delivery never came. It’s, like, really annoying. Uh, I want a refund or whatever.  \n",
       "4             Hi, I’m Dr. Alan Turing, and I was inquiring about the status of my reimbursement request. It was submitted on the 10th of June. Please advise.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the transcripts\n",
    "df = pd.read_csv(r\"C:\\Users\\Adam\\Desktop\\main\\programming\\machine learning\\voice call analyzer\\data\\sample_transcripts.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17d8e6c1-48d8-4c8b-89e1-185534b482ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word count col\n",
    "df['word_count'] = df['transcript'].apply(lambda x: len([w for w in word_tokenize(x) if w.isalpha()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "804f2d05-9da9-49f3-9a8c-682f1dad91fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>transcript</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hello, my name is John Doe. I’m calling from New York regarding an issue with my internet connection. It’s been down since Monday. Can you help me fix it?</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uh, so like, um, I bought this thing and it’s, uh, not working. You know? Like, I need, uh, help or something.</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Good afternoon, I’m Maria Sanchez. I placed an order last week and I haven't received a confirmation email. Could you check on that for me?</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Yeah hi, yeah, the delivery never came. It’s, like, really annoying. Uh, I want a refund or whatever.</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Hi, I’m Dr. Alan Turing, and I was inquiring about the status of my reimbursement request. It was submitted on the 10th of June. Please advise.</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transcript_id  \\\n",
       "0              1   \n",
       "1              2   \n",
       "2              3   \n",
       "3              4   \n",
       "4              5   \n",
       "\n",
       "                                                                                                                                                   transcript  \\\n",
       "0  Hello, my name is John Doe. I’m calling from New York regarding an issue with my internet connection. It’s been down since Monday. Can you help me fix it?   \n",
       "1                                              Uh, so like, um, I bought this thing and it’s, uh, not working. You know? Like, I need, uh, help or something.   \n",
       "2                 Good afternoon, I’m Maria Sanchez. I placed an order last week and I haven't received a confirmation email. Could you check on that for me?   \n",
       "3                                                       Yeah hi, yeah, the delivery never came. It’s, like, really annoying. Uh, I want a refund or whatever.   \n",
       "4             Hi, I’m Dr. Alan Turing, and I was inquiring about the status of my reimbursement request. It was submitted on the 10th of June. Please advise.   \n",
       "\n",
       "   word_count  \n",
       "0          31  \n",
       "1          23  \n",
       "2          26  \n",
       "3          19  \n",
       "4          25  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3b934d-0d8d-4052-a28b-5c43d1d5ae9f",
   "metadata": {},
   "source": [
    "### 2. Extract Information\n",
    "We’ll extract these features:\n",
    "* Basic NLP metrics\n",
    "* Sentence structure\n",
    "* Sentiment\n",
    "* Filler words\n",
    "* Named Entity Recognition (e.g., names, orgs)\n",
    "* POS diversity\n",
    "* Grammar error count\n",
    "This information will help us to check if transcription is good for Rnglish level measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b4fd421-f700-4176-b557-950541166af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7873fb73-dc81-4c6c-8c88-b3e9b75bfea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(transcript: str):\n",
    "    \"\"\"\n",
    "    Extracts linguistic, grammatical, and semantic features from a transcript.\n",
    "    Returns a dictionary with metrics such as word count, uniqueness, sentence length,\n",
    "    sentiment, filler ratio, named entities, POS diversity, and grammar score.\n",
    "    \"\"\"\n",
    "    doc = nlp(transcript)\n",
    "\n",
    "    # basic NLP metrics\n",
    "    word_count = len([token.text for token in doc if token.is_alpha or token.is_digit])\n",
    "    unique_words = set(token.text.lower() for token in doc if token.is_alpha)\n",
    "    unique_ratio = len(unique_words) / word_count if word_count else 0\n",
    "    \n",
    "    # sentence structure\n",
    "    sentences = list(doc.sents)\n",
    "    avg_sentence_len = sum(len(sent) for sent in sentences) / len(sentences) if sentences else 0\n",
    "\n",
    "    # sentiment\n",
    "    sentiment = TextBlob(transcript).sentiment.polarity\n",
    "\n",
    "    # filler words\n",
    "    fillers = re.findall(r'\\b(uh|um|you know|like|erm|hmm)\\b', transcript.lower())\n",
    "    filler_ratio = len(fillers) / word_count if word_count else 0\n",
    "\n",
    "    # named Entity Recognition (e.g., names, orgs)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "    # POS diversity\n",
    "    pos_tags = [token.pos_ for token in doc]\n",
    "    pos_diversity = len(set(pos_tags)) / len(pos_tags) if pos_tags else 0\n",
    "    \n",
    "    # grammar error count\n",
    "    grammar_matches = tool.check(transcript)\n",
    "    grammar_errors = len(grammar_matches)\n",
    "    grammar_score = max(0, 1 - (grammar_errors / len(sentences))) if sentences else 0\n",
    "    \n",
    "    return {\n",
    "        \"word_count\": word_count,\n",
    "        \"unique_ratio\": unique_ratio,\n",
    "        \"avg_sentence_len\": avg_sentence_len,\n",
    "        \"sentiment\": sentiment,\n",
    "        \"filler_ratio\": filler_ratio,\n",
    "        \"entities\": entities,\n",
    "        \"pos_diversity\": pos_diversity,\n",
    "        \"grammar_errors\": grammar_errors,\n",
    "        \"grammar_score\": round(grammar_score, 2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf4edfe8-57a2-4571-ad7e-87f2c42e91bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample ='Hello, my name is John Doe. I’m calling from New York regarding an issue with my internet connection. It’s been down since Monday. Can you help me fix it?\t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "15ade4cd-8737-4da4-88d0-a66e21b25e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Info: {'word_count': 29, 'unique_ratio': 0.9310344827586207, 'avg_sentence_len': 9.25, 'sentiment': -0.009595959595959616, 'filler_ratio': 0.0, 'entities': [('John Doe', 'PERSON'), ('New York', 'GPE'), ('Monday', 'DATE')], 'pos_diversity': 0.32432432432432434, 'grammar_errors': 0, 'grammar_score': 1.0}\n"
     ]
    }
   ],
   "source": [
    "info = extract_info(sample)\n",
    "print(\"Extracted Info:\", info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff07e3a-c235-4143-9e38-0db347dca746",
   "metadata": {},
   "source": [
    "###  3.Is good?\n",
    "The next step is to check if our transcription is good for further preprocessing. It can help us determine the accuracy of prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "59138692-65fc-480e-b1c4-674a46e76ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_transcription_good(info: dict):\n",
    "    \"\"\"\n",
    "    Evaluates if a transcription meets quality thresholds for word count, \n",
    "    lexical richness, sentiment neutrality, filler frequency, and presence of named entities.\n",
    "    Returns True if quality is sufficient, otherwise False.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        info[\"word_count\"] >= 30 and\n",
    "        info[\"unique_ratio\"] >= 0.4 and\n",
    "        abs(info[\"sentiment\"]) < 0.8 and  \n",
    "        info[\"filler_ratio\"] < 0.05 and\n",
    "        any(label in ['PERSON', 'ORG', 'GPE'] for _, label in info[\"entities\"])  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aeb62806-0afd-4f43-8751-4590f97c082d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is transcription good? False\n"
     ]
    }
   ],
   "source": [
    "print(\"Is transcription good?\", is_transcription_good(info))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e8649f-2df6-4f9f-8f83-178a18cd9a47",
   "metadata": {},
   "source": [
    "### 4. English level\n",
    "Finally we need to measure English lvl. Logic for measuring language proficiency level is based on rule-based heuristics inspired by CEFR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d659ab5-4171-4233-98a8-2c2d54dd012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_proficiency(info: dict, quality_threshold: float = 0.5):\n",
    "    \"\"\"\n",
    "    Estimates language proficiency level (A1 to C2+) based on various linguistic metrics,\n",
    "    including word count, lexical diversity, sentence length, filler usage, grammar, and POS diversity.\n",
    "    Returns a CEFR-aligned proficiency level label.\n",
    "    \"\"\"\n",
    "    level_score = 0\n",
    "\n",
    "    if info[\"word_count\"] > 50: level_score += 1\n",
    "    if info[\"unique_ratio\"] > 0.4: level_score += 1\n",
    "    if info[\"avg_sentence_len\"] > 12: level_score += 1\n",
    "    if info[\"filler_ratio\"] < 0.03: level_score += 1\n",
    "    if info[\"grammar_score\"] > 0.75: level_score += 1\n",
    "    if info[\"pos_diversity\"] > 0.3: level_score += 1\n",
    "\n",
    "    # rule-based scoring\n",
    "    levels = {\n",
    "        0: \"A1 (Beginner)\",\n",
    "        1: \"A2 (Elementary)\",\n",
    "        2: \"B1 (Intermediate)\",\n",
    "        3: \"B2 (Upper Intermediate)\",\n",
    "        4: \"C1 (Advanced)\",\n",
    "        5: \"C2 (Proficient)\",\n",
    "        6: \"C2+ (Near-native)\"\n",
    "    }\n",
    "    return levels.get(level_score, \"A1 (Beginner)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "74144561-11bc-41de-8312-3bc8eedf403e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated English level: C1 (Advanced)\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimated English level:\", estimate_proficiency(info))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439fec73-ce36-4396-a4e4-b5a356b0fd62",
   "metadata": {},
   "source": [
    "### 5. Let's connect everthing!\n",
    "Finally, now we can enjoy the fruit of our work! Now I just need to simply connect all the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "669f3265-715c-42b5-9e55-60ccde80f63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_transcripts(df):\n",
    "    results = []\n",
    "    counter = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        counter+=1\n",
    "        print(f'Row nr. {counter}\\n')\n",
    "        transcript = row['transcript']\n",
    "        info = extract_info(transcript)\n",
    "        is_good = is_transcription_good(info)\n",
    "        level = estimate_proficiency(info)\n",
    "\n",
    "        results.append({\n",
    "            'id': row.get(\"id\",idx),\n",
    "            'word_count':info['word_count'],\n",
    "            'unique_ratio':round(info['unique_ratio'],2),\n",
    "            \"avg_sentence_len\": round(info[\"avg_sentence_len\"], 2),\n",
    "            \"sentiment\": round(info[\"sentiment\"], 2),\n",
    "            \"filler_ratio\": round(info[\"filler_ratio\"], 2),\n",
    "            \"grammar_score\": info[\"grammar_score\"],\n",
    "            \"pos_diversity\": round(info[\"pos_diversity\"], 2),\n",
    "            \"entities\": info[\"entities\"],\n",
    "            \"grammar_errors\": info[\"grammar_errors\"],\n",
    "            \"is_good\": is_good,\n",
    "            \"estimated_level\": level\n",
    "        })\n",
    "        print(f'Results: {results}')\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b1a839e7-31cd-46c2-a08e-b6b2105e0ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row nr. 1\n",
      "\n",
      "Results: [{'id': 0, 'word_count': 29, 'unique_ratio': 0.93, 'avg_sentence_len': 9.0, 'sentiment': -0.01, 'filler_ratio': 0.0, 'grammar_score': 1.0, 'pos_diversity': 0.31, 'entities': [('John Doe', 'PERSON'), ('New York', 'GPE'), ('Monday', 'DATE')], 'grammar_errors': 0, 'is_good': False, 'estimated_level': 'C1 (Advanced)'}]\n",
      "Row nr. 2\n",
      "\n",
      "Results: [{'id': 0, 'word_count': 29, 'unique_ratio': 0.93, 'avg_sentence_len': 9.0, 'sentiment': -0.01, 'filler_ratio': 0.0, 'grammar_score': 1.0, 'pos_diversity': 0.31, 'entities': [('John Doe', 'PERSON'), ('New York', 'GPE'), ('Monday', 'DATE')], 'grammar_errors': 0, 'is_good': False, 'estimated_level': 'C1 (Advanced)'}, {'id': 1, 'word_count': 22, 'unique_ratio': 0.82, 'avg_sentence_len': 11.33, 'sentiment': 0.0, 'filler_ratio': 0.32, 'grammar_score': 0.67, 'pos_diversity': 0.26, 'entities': [], 'grammar_errors': 1, 'is_good': False, 'estimated_level': 'A2 (Elementary)'}]\n",
      "Row nr. 3\n",
      "\n",
      "Results: [{'id': 0, 'word_count': 29, 'unique_ratio': 0.93, 'avg_sentence_len': 9.0, 'sentiment': -0.01, 'filler_ratio': 0.0, 'grammar_score': 1.0, 'pos_diversity': 0.31, 'entities': [('John Doe', 'PERSON'), ('New York', 'GPE'), ('Monday', 'DATE')], 'grammar_errors': 0, 'is_good': False, 'estimated_level': 'C1 (Advanced)'}, {'id': 1, 'word_count': 22, 'unique_ratio': 0.82, 'avg_sentence_len': 11.33, 'sentiment': 0.0, 'filler_ratio': 0.32, 'grammar_score': 0.67, 'pos_diversity': 0.26, 'entities': [], 'grammar_errors': 1, 'is_good': False, 'estimated_level': 'A2 (Elementary)'}, {'id': 2, 'word_count': 25, 'unique_ratio': 0.92, 'avg_sentence_len': 10.33, 'sentiment': 0.35, 'filler_ratio': 0.0, 'grammar_score': 1.0, 'pos_diversity': 0.35, 'entities': [('afternoon', 'TIME'), ('Maria Sanchez', 'PERSON'), ('last week', 'DATE')], 'grammar_errors': 0, 'is_good': False, 'estimated_level': 'C1 (Advanced)'}]\n",
      "Row nr. 4\n",
      "\n",
      "Results: [{'id': 0, 'word_count': 29, 'unique_ratio': 0.93, 'avg_sentence_len': 9.0, 'sentiment': -0.01, 'filler_ratio': 0.0, 'grammar_score': 1.0, 'pos_diversity': 0.31, 'entities': [('John Doe', 'PERSON'), ('New York', 'GPE'), ('Monday', 'DATE')], 'grammar_errors': 0, 'is_good': False, 'estimated_level': 'C1 (Advanced)'}, {'id': 1, 'word_count': 22, 'unique_ratio': 0.82, 'avg_sentence_len': 11.33, 'sentiment': 0.0, 'filler_ratio': 0.32, 'grammar_score': 0.67, 'pos_diversity': 0.26, 'entities': [], 'grammar_errors': 1, 'is_good': False, 'estimated_level': 'A2 (Elementary)'}, {'id': 2, 'word_count': 25, 'unique_ratio': 0.92, 'avg_sentence_len': 10.33, 'sentiment': 0.35, 'filler_ratio': 0.0, 'grammar_score': 1.0, 'pos_diversity': 0.35, 'entities': [('afternoon', 'TIME'), ('Maria Sanchez', 'PERSON'), ('last week', 'DATE')], 'grammar_errors': 0, 'is_good': False, 'estimated_level': 'C1 (Advanced)'}, {'id': 3, 'word_count': 18, 'unique_ratio': 0.94, 'avg_sentence_len': 9.0, 'sentiment': -0.8, 'filler_ratio': 0.11, 'grammar_score': 1.0, 'pos_diversity': 0.33, 'entities': [], 'grammar_errors': 0, 'is_good': False, 'estimated_level': 'B2 (Upper Intermediate)'}]\n",
      "Row nr. 5\n",
      "\n",
      "Results: [{'id': 0, 'word_count': 29, 'unique_ratio': 0.93, 'avg_sentence_len': 9.0, 'sentiment': -0.01, 'filler_ratio': 0.0, 'grammar_score': 1.0, 'pos_diversity': 0.31, 'entities': [('John Doe', 'PERSON'), ('New York', 'GPE'), ('Monday', 'DATE')], 'grammar_errors': 0, 'is_good': False, 'estimated_level': 'C1 (Advanced)'}, {'id': 1, 'word_count': 22, 'unique_ratio': 0.82, 'avg_sentence_len': 11.33, 'sentiment': 0.0, 'filler_ratio': 0.32, 'grammar_score': 0.67, 'pos_diversity': 0.26, 'entities': [], 'grammar_errors': 1, 'is_good': False, 'estimated_level': 'A2 (Elementary)'}, {'id': 2, 'word_count': 25, 'unique_ratio': 0.92, 'avg_sentence_len': 10.33, 'sentiment': 0.35, 'filler_ratio': 0.0, 'grammar_score': 1.0, 'pos_diversity': 0.35, 'entities': [('afternoon', 'TIME'), ('Maria Sanchez', 'PERSON'), ('last week', 'DATE')], 'grammar_errors': 0, 'is_good': False, 'estimated_level': 'C1 (Advanced)'}, {'id': 3, 'word_count': 18, 'unique_ratio': 0.94, 'avg_sentence_len': 9.0, 'sentiment': -0.8, 'filler_ratio': 0.11, 'grammar_score': 1.0, 'pos_diversity': 0.33, 'entities': [], 'grammar_errors': 0, 'is_good': False, 'estimated_level': 'B2 (Upper Intermediate)'}, {'id': 4, 'word_count': 24, 'unique_ratio': 0.83, 'avg_sentence_len': 10.67, 'sentiment': 0.0, 'filler_ratio': 0.0, 'grammar_score': 1.0, 'pos_diversity': 0.31, 'entities': [('Alan Turing', 'PERSON'), ('the 10th of June', 'DATE')], 'grammar_errors': 0, 'is_good': False, 'estimated_level': 'C1 (Advanced)'}]\n"
     ]
    }
   ],
   "source": [
    "evaluated_df = process_transcripts(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f7345422-7274-40a0-8da6-9460d78acfb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_ratio</th>\n",
       "      <th>avg_sentence_len</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>filler_ratio</th>\n",
       "      <th>grammar_score</th>\n",
       "      <th>pos_diversity</th>\n",
       "      <th>entities</th>\n",
       "      <th>grammar_errors</th>\n",
       "      <th>is_good</th>\n",
       "      <th>estimated_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.93</td>\n",
       "      <td>9.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>[(John Doe, PERSON), (New York, GPE), (Monday, DATE)]</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>C1 (Advanced)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.82</td>\n",
       "      <td>11.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.26</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>A2 (Elementary)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.92</td>\n",
       "      <td>10.33</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>[(afternoon, TIME), (Maria Sanchez, PERSON), (last week, DATE)]</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>C1 (Advanced)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0.94</td>\n",
       "      <td>9.00</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>B2 (Upper Intermediate)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>0.83</td>\n",
       "      <td>10.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>[(Alan Turing, PERSON), (the 10th of June, DATE)]</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>C1 (Advanced)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  word_count  unique_ratio  avg_sentence_len  sentiment  filler_ratio  \\\n",
       "0   0          29          0.93              9.00      -0.01          0.00   \n",
       "1   1          22          0.82             11.33       0.00          0.32   \n",
       "2   2          25          0.92             10.33       0.35          0.00   \n",
       "3   3          18          0.94              9.00      -0.80          0.11   \n",
       "4   4          24          0.83             10.67       0.00          0.00   \n",
       "\n",
       "   grammar_score  pos_diversity  \\\n",
       "0           1.00           0.31   \n",
       "1           0.67           0.26   \n",
       "2           1.00           0.35   \n",
       "3           1.00           0.33   \n",
       "4           1.00           0.31   \n",
       "\n",
       "                                                          entities  \\\n",
       "0            [(John Doe, PERSON), (New York, GPE), (Monday, DATE)]   \n",
       "1                                                               []   \n",
       "2  [(afternoon, TIME), (Maria Sanchez, PERSON), (last week, DATE)]   \n",
       "3                                                               []   \n",
       "4                [(Alan Turing, PERSON), (the 10th of June, DATE)]   \n",
       "\n",
       "   grammar_errors  is_good          estimated_level  \n",
       "0               0    False            C1 (Advanced)  \n",
       "1               1    False          A2 (Elementary)  \n",
       "2               0    False            C1 (Advanced)  \n",
       "3               0    False  B2 (Upper Intermediate)  \n",
       "4               0    False            C1 (Advanced)  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "13954bd5-8a0d-4aec-8e2f-5a88acd5b313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the result\n",
    "df.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8b96e9-0984-41a1-b14a-4ab1e9f82916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
